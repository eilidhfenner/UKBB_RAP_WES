{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Running VEP on matrix tables\n",
    "This script reads in matrix tables formed in stage 1 and annotates variants with their function using VEP. It then writes out these annotations as a hail table. These can then be annotated back to a matrix table where required.\n",
    "\n",
    "For this stage, I used a mem2_ssd1_v2_x8 instance with 60 nodes. Setting up the VEP in an instance is quite slow and I therefore used the same instance to loop through each chromosome once the VEP had been set up. This stage cost a total of ~Â£45 and took around 3 hours.\n",
    "\n",
    "The outputted hail tables are stored within DNAX. These total 11GB. \n",
    "\n",
    "## Set up Hail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip-installed Hail requires additional configuration options in Spark referring\n",
      "  to the path to the Hail Python module directory HAIL_DIR,\n",
      "  e.g. /path/to/python/site-packages/hail:\n",
      "    spark.jars=HAIL_DIR/backend/hail-all-spark.jar\n",
      "    spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar\n",
      "    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.2.3\n",
      "SparkUI available at http://ip-10-60-175-114.eu-west-2.compute.internal:8081\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.116-cd64e0876c94\n",
      "LOGGING: writing to /opt/notebooks/hail-20240802-1356-0.2.116-cd64e0876c94.log\n"
     ]
    }
   ],
   "source": [
    "# Initialise hail and spark logs? Running this cell will output a red-colored message- this is expected.\n",
    "# The 'Welcome to Hail' message in the output will indicate that Hail is ready to use in the notebook.\n",
    "\n",
    "# CHanging spark configuration?? \n",
    "import pyspark.sql\n",
    "\n",
    "config = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max', '128')])\n",
    "sc = pyspark.SparkContext(conf=config) \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import hail as hl\n",
    "builder = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .enableHiveSupport()\n",
    ")\n",
    "spark = builder.getOrCreate()\n",
    "hl.init(sc=sc)\n",
    "\n",
    "# Check this has actually worked though?!!! \n",
    "\n",
    "import dxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate variants with VEP and write annotations out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the chromosome you're working with \n",
    "for chr in range (1,24):\n",
    "    print(f'Annotating chr {chr} with VEP ... ')\n",
    "\n",
    "    # Read in MT from stage 1\n",
    "    mt=hl.read_matrix_table(f\"dnax://database-GgPbpq8J637bkp84VQyQ83X9/chromosome_{chr}_post_genoqc_final.mt\")\n",
    "    # Check this table is as you'd expect\n",
    "    print(mt.count())\n",
    "\n",
    "\n",
    "    # Run VEP using a json plugin file to annotate with loftee too \n",
    "    ## This json file is saved on git alongside this script. \n",
    "    mt=hl.vep(mt, \"file:///mnt/project/WES_QC/annotations/04a_helper_file_config_plugin_details.json\")\n",
    "\n",
    "\n",
    "    # Annotate each row (variant) with the most severe consequence\n",
    "    ## Set up annotations\n",
    "    PTV_annotations = hl.set([\"splice_acceptor_variant\", \"splice_donor_variant\", \"stop_gained\", \"frameshift_variant\"])\n",
    "    NS_annotations = hl.set([\"splice_acceptor_variant\", \"splice_donor_variant\", \"stop_gained\", \"inframe_insertion\", \"inframe_deletion\", \"inframe_insertion\", \"missense_variant\", \"stop_lost\", \"start_lost\", \"frameshift_variant\"])\n",
    "    Miss_annotations = hl.set([\"missense_variant\"])\n",
    "    S_annotations = hl.set([\"synonymous_variant\"])\n",
    "    # Annotate\n",
    "    mt = mt.annotate_rows(LoF_worstCsq = (PTV_annotations.contains(mt.vep.most_severe_consequence)),\n",
    "                          NS_worstCsq = (NS_annotations.contains(mt.vep.most_severe_consequence)),\n",
    "                          Miss_worstCsq = (Miss_annotations.contains(mt.vep.most_severe_consequence)),\n",
    "                          Syn_worstCsq = (S_annotations.contains(mt.vep.most_severe_consequence)),\n",
    "                          gene_symbol_worstCsq = (mt.vep.transcript_consequences.find(lambda x : x.consequence_terms.contains(mt.vep.most_severe_consequence)).gene_symbol),\n",
    "                          gene_id_worstCsq = (mt.vep.transcript_consequences.find(lambda x : x.consequence_terms.contains(mt.vep.most_severe_consequence)).gene_id)\n",
    "                         )\n",
    "    \n",
    "\n",
    "    # Filter to just rows (which contain annotations) so annotations can be written out as hail tables. \n",
    "    ht=mt.rows()\n",
    "\n",
    "\n",
    "    # Write out as a hail table using DNAX which can then be reannotated to hail tables at a later point\n",
    "    db_name = f\"vep_annotations_from_mts\"\n",
    "    ht_name = f\"chr_{chr}_annotations_LoFTEE_updated.ht\"\n",
    "    # Create database in DNAX\n",
    "    stmt = f\"CREATE DATABASE IF NOT EXISTS {db_name} LOCATION 'dnax://'\"\n",
    "    print(stmt)\n",
    "    spark.sql(stmt).show()\n",
    "    # Store MT in DNAX\n",
    "    import dxpy\n",
    "    # Find database ID of newly created database using dxpy method\n",
    "    db_uri = dxpy.find_one_data_object(name=f\"{db_name}\", classname=\"database\")['id']\n",
    "    url = f\"dnax://{db_uri}/{ht_name}\" # Note: the dnax url must follow this format to properly save MT to DNAX\n",
    "    # Before this step, the Hail MatrixTable is just an object in memory. To persist it and be able to access \n",
    "    # # it later, the notebook needs to write it into a persistent filesystem (in this case DNAX).\n",
    "    ht.checkpoint(url) # Note: output should describe size of MT (i.e. number of rows, columns, partitions) \n",
    "\n",
    "\n",
    "    # Check the file has the annotations you want\n",
    "    ## Initially when using the VEP on the RAP I had issues with lots of missing LoFTEE annotations. \n",
    "    ## Below, I check if most variants annotated as LoF have at least some transcripts with LoFTEE high or low confidence flags. \n",
    "    LoF=mt.filter_rows(mt.LoF_worstCsq==True)\n",
    "    LoF.vep.transcript_consequences.lof.show(10) #Check p much every row has a HC or LC somewhere. If not, still issue w LoFTEE!! \n",
    "\n",
    "    print(f\"VEP annotations for chr {chr} complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
