{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. Sex imputation\n",
    "For this stage, I used a mem1_ssd1_v2_x8 instance with 2 nodes. This took a total of 30 minutes, and cost Â£0.20. \n",
    "\n",
    "## Set up environment\n",
    "Make sure you run this block only once. You'll get errors if you try to initialise Hail multiple times. If you do do this, you'll need to restart the kernel, and then initialise Hail only once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip-installed Hail requires additional configuration options in Spark referring\n",
      "  to the path to the Hail Python module directory HAIL_DIR,\n",
      "  e.g. /path/to/python/site-packages/hail:\n",
      "    spark.jars=HAIL_DIR/backend/hail-all-spark.jar\n",
      "    spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar\n",
      "    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.2.3\n",
      "SparkUI available at http://ip-10-60-68-12.eu-west-2.compute.internal:8081\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.116-cd64e0876c94\n",
      "LOGGING: writing to /opt/notebooks/hail-20240419-0851-0.2.116-cd64e0876c94.log\n"
     ]
    }
   ],
   "source": [
    "# Initialise hail and spark logs? Running this cell will output a red-colored message- this is expected.\n",
    "# The 'Welcome to Hail' message in the output will indicate that Hail is ready to use in the notebook.\n",
    "import pyspark.sql\n",
    "\n",
    "config = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max', '128')])\n",
    "sc = pyspark.SparkContext(conf=config) \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import hail as hl\n",
    "builder = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .enableHiveSupport()\n",
    ")\n",
    "spark = builder.getOrCreate()\n",
    "hl.init(sc=sc)\n",
    "\n",
    "import dxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in X chromosome\n",
    "Here, you read in the matrix table for the X chromosome and check it is the size you'd expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425743, 469151)\n",
      "2000\n",
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "    'sample_qc': struct {\n",
      "        dp_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        gq_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        call_rate: float64, \n",
      "        n_called: int64, \n",
      "        n_not_called: int64, \n",
      "        n_filtered: int64, \n",
      "        n_hom_ref: int64, \n",
      "        n_het: int64, \n",
      "        n_hom_var: int64, \n",
      "        n_non_ref: int64, \n",
      "        n_singleton: int64, \n",
      "        n_snp: int64, \n",
      "        n_insertion: int64, \n",
      "        n_deletion: int64, \n",
      "        n_transition: int64, \n",
      "        n_transversion: int64, \n",
      "        n_star: int64, \n",
      "        r_ti_tv: float64, \n",
      "        r_het_hom_var: float64, \n",
      "        r_insertion_deletion: float64\n",
      "    }\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh38>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'qual': float64\n",
      "    'filters': set<str>\n",
      "    'info': struct {\n",
      "        AF: array<float64>, \n",
      "        AQ: array<int32>, \n",
      "        AC: array<int32>, \n",
      "        AN: int32\n",
      "    }\n",
      "    'a_index': int32\n",
      "    'was_split': bool\n",
      "    'variant_qc': struct {\n",
      "        dp_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        gq_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        AC: array<int32>, \n",
      "        AF: array<float64>, \n",
      "        AN: int32, \n",
      "        homozygote_count: array<int32>, \n",
      "        call_rate: float64, \n",
      "        n_called: int64, \n",
      "        n_not_called: int64, \n",
      "        n_filtered: int64, \n",
      "        n_het: int64, \n",
      "        n_non_ref: int64, \n",
      "        het_freq_hwe: float64, \n",
      "        p_value_hwe: float64, \n",
      "        p_value_excess_het: float64\n",
      "    }\n",
      "    'LCR': bool\n",
      "    'variant_gq_over_40': bool\n",
      "    'variant_call_rate_over_90_percent': bool\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'GT': call\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chr=23\n",
    "#Annotate variants to the matrix table \n",
    "mt=hl.read_matrix_table(f\"dnax://database-Ggy1X3QJ637qBKGypjy9y9f4/chromosome_{chr}_post_geno_sample_and_var_qc.mt\")\n",
    "# Check this table is as you'd expect\n",
    "print(mt.count())\n",
    "print(mt.n_partitions())\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to high quality, non-rare variants.\n",
    "Filter to variants with a high call rate and remove rare variants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297719, 469151)\n",
      "(677, 469151)\n"
     ]
    }
   ],
   "source": [
    "mt=mt.filter_rows(mt.variant_qc.call_rate>=0.97)\n",
    "print(mt.count()) # 297719 variants remain following call rate filtering\n",
    "mt=mt.filter_rows((mt.variant_qc.AF[1]>.01) & (mt.variant_qc.AF[1]<.99))\n",
    "print(mt.count()) # 677 variants remain following AF filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute sex \n",
    "Now use the hail impute_sex function to impute sex based on these non-rare, high call-rate variants. Then write out the outputs of this imputation to a .tsv file and save this out to the project folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 09:10:05.831 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\n",
      "2024-04-19 09:18:53.580 Hail: INFO: Coerced sorted dataset\n",
      "2024-04-19 09:18:54.696 Hail: INFO: merging 17 files totalling 19.6M...\n",
      "2024-04-19 09:18:54.779 Hail: INFO: while writing:\n",
      "    imputed_sex.tsv\n",
      "  merge time: 82.777ms\n"
     ]
    }
   ],
   "source": [
    "imputed=hl.impute_sex(mt.GT)\n",
    "imputed.export('imputed_sex.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/cluster/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/cluster/dnax/jars/dnanexus-api-0.1.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Reload4jLoggerFactory]\n",
      "2024-04-19 09:21:24,633 WARN metrics.MetricsReporter: Unable to initialize metrics scraping configurations from hive-site.xml. Message:InputStream cannot be null\n",
      "2024-04-19 09:21:24,730 WARN service.DNAxApiSvc: Using default configurations. Unable to find dnanexus.conf.location=null\n",
      "2024-04-19 09:21:24,730 INFO service.DNAxApiSvc: apiserver connection-pool config. MaxPoolSize=10, MaxPoolPerRoute=10,MaxWaitTimeout=60000\n",
      "2024-04-19 09:21:24,730 INFO service.DNAxApiSvc: initializing http connection manager pools\n",
      "2024-04-19 09:21:24,910 INFO service.DNAxApiSvc: Worker process - IdleConnectionMonitorThread disabled\n",
      "2024-04-19 09:21:24,910 INFO service.DNAxApiSvc: Worker process - IdleConnectionMonitorThread disabled\n",
      "2024-04-19 09:21:24,911 INFO service.DNAxApiSvc: initializing DNAxApiSvc\n",
      "2024-04-19 09:21:25,559 WARN service.DNAxApiSvc: Shutting down Runtime service for Connection Pools\n",
      "2024-04-19 09:21:25,559 INFO service.DNAxApiSvc: shutting down httpClientConnManager\n",
      "2024-04-19 09:21:25,560 INFO service.DNAxApiSvc: shutting down httpsClientConnManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                          file-GjV3P5QJ637vYkXPKyF6qp3Q\n",
      "Class                       file\n",
      "Project                     project-Gfj1VXjJ637kVQFzkY7xyQz2\n",
      "Folder                      /\n",
      "Name                        imputed_sex.tsv\n",
      "State                       closing\n",
      "Visibility                  visible\n",
      "Types                       -\n",
      "Properties                  -\n",
      "Tags                        -\n",
      "Outgoing links              -\n",
      "Created                     Fri Apr 19 09:21:26 2024\n",
      "Created by                  efenner\n",
      " via the job                job-GjV2gyjJ637Qk9BGXJjv8PPv\n",
      "Last modified               Fri Apr 19 09:21:27 2024\n",
      "Media type                  \n",
      "archivalState               \"live\"\n",
      "cloudAccount                \"cloudaccount-dnanexus\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -get imputed_sex.tsv\n",
    "dx upload imputed_sex.tsv --destination ./WES_QC/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y chromosome QC \n",
    "\n",
    "Filter to high quality variants on the Y-chromsome (non-PAR variants with mean depth >3.5) and then write out sample QC metrics based on these for use in inferring genetic sex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in original y chromosome pVCF (we want pre genotype QC values for this)\n",
    "chr=24\n",
    "file_url = f\"file:///mnt/project/Bulk/Exome sequences/Population level exome OQFE variants, pVCF format - final release/*_cY_*.vcf.gz\"\n",
    "a=hl.import_vcf(file_url, \n",
    "                 force_bgz=True,\n",
    "                 reference_genome='GRCh38',\n",
    "                 array_elements_required=False).write(f\"./chr_{chr}_initial_mt.mt\", overwrite=True)\n",
    "mt=hl.read_matrix_table(f\"./chr_{chr}_initial_mt.mt\")\n",
    "print(f\"Num partitions: {mt.n_partitions()}\")\n",
    "# Check this table is as you'd expect\n",
    "print(mt.count())\n",
    "mt.describe()\n",
    "\n",
    "# Annotate rows with whether they are in the Y chromosome PAR regions\n",
    "mt = mt.annotate_rows(in_par=mt.locus.in_autosome_or_par()) \n",
    "# Look at this field \n",
    "mt.in_par.show(10)\n",
    "mt.in_par.summarize()\n",
    "# Count vars in par/non-par regions \n",
    "par_counts = mt.aggregate_rows(hl.struct(\n",
    "    in_par=hl.agg.count_where(mt.in_par),\n",
    "    not_in_par=hl.agg.count_where(~mt.in_par)\n",
    "))\n",
    "print(f\"Variants in PAR region: {par_counts.in_par}\")\n",
    "print(f\"Variants outside PAR region: {par_counts.not_in_par}\") # There are no par regions here - think the variant caller only called non-PAR regions for Y chromosome. \n",
    "\n",
    "# Filter on depth\n",
    "mt = hl.variant_qc(mt)\n",
    "print(mt.count())\n",
    "mt=mt.filter_rows(mt.variant_qc.dp_stats.mean>=3.5)\n",
    "print(mt.count()) # 8,737 variants remain\n",
    "\n",
    "mt = hl.sample_qc(mt)\n",
    "sample_qc=mt.cols()\n",
    "sample_qc.describe()\n",
    "sample_qc.export(f\"chr_{chr}sample_qc_for_sex_inference.csv\", delimiter=\",\")\n",
    "print('Sample QC table written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -get ./*sample_qc_for_sex_inference.csv ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Upload these to that dir within your project\n",
    "dx upload ./*sample_qc_for_sex_inference.csv --destination ./WES_QC/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
